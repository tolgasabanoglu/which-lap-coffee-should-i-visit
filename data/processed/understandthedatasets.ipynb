{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading airquality from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_pm25_daily.gpkg ...\n",
      "airquality: 4752 rows, columns: ['name', 'address', 'lat', 'lon', 'date', 'pm25_aod_proxy', 'geometry']\n",
      "\n",
      "Loading elevation from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_elevation.gpkg ...\n",
      "elevation: 16 rows, columns: ['name', 'address', 'lat', 'lon', 'rating', 'user_ratings_total', 'place_id', 'elevation_m', 'geometry']\n",
      "\n",
      "Loading weather from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_historical_weather.gpkg ...\n",
      "weather: 4768 rows, columns: ['weather_date', 'temp_max', 'temp_min', 'precip_mm', 'name', 'address', 'lat', 'lon', 'rating', 'user_ratings_total', 'season', 'geometry']\n",
      "\n",
      "Loading ndvi from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_ndvi_daily.gpkg ...\n",
      "ndvi: 4752 rows, columns: ['name', 'address', 'lat', 'lon', 'date', 'ndvi', 'geometry']\n",
      "\n",
      "Loading nightlights from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_nightlights_daily.gpkg ...\n",
      "nightlights: 4752 rows, columns: ['name', 'address', 'lat', 'lon', 'date', 'nightlight', 'geometry']\n",
      "\n",
      "Loading open_bars from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_with_open_bars.gpkg ...\n",
      "open_bars: 16 rows, columns: ['name', 'address', 'lat', 'lon', 'rating', 'user_ratings_total', 'place_id', 'open_bars_count_500m', 'geometry']\n",
      "\n",
      "Loading parks from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_with_park_counts.gpkg ...\n",
      "parks: 16 rows, columns: ['name', 'address', 'lat', 'lon', 'rating', 'user_ratings_total', 'place_id', 'parks_count_1km', 'geometry']\n",
      "\n",
      "### airquality\n",
      "Date range: 2025-01-01 - 2025-10-24\n",
      "\n",
      "\n",
      "### elevation\n",
      "\n",
      "\n",
      "### weather\n",
      "Weather date range: 2025-01-01 - 2025-10-25\n",
      "\n",
      "\n",
      "### ndvi\n",
      "Date range: 2025-01-01 - 2025-10-24\n",
      "\n",
      "\n",
      "### nightlights\n",
      "Date range: 2025-01-01 - 2025-10-24\n",
      "\n",
      "\n",
      "### open_bars\n",
      "\n",
      "\n",
      "### parks\n",
      "\n",
      "\n",
      "Removing duplicate columns: ['rating_elevation', 'user_ratings_total_elevation', 'rating_parks', 'user_ratings_total_parks', 'place_id_parks', 'rating_open_bars', 'user_ratings_total_open_bars', 'place_id_open_bars']\n",
      "✅ Expanded dataset covers 297 days × 16 cafes = 4,752 rows\n",
      "✅ Merged dataset saved: /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_final_merged.csv\n",
      "Columns: ['date', 'name', 'lat', 'lon', 'address', 'pm25_aod_proxy', 'geometry', 'weather_date', 'temp_max', 'temp_min', 'precip_mm', 'cafe_rating', 'cafe_user_ratings_total', 'season', 'ndvi', 'nightlight', 'cafe_place_id', 'elevation_m', 'parks_count_1km', 'open_bars_count_500m']\n",
      "Number of rows: 4752\n",
      "Sample rows:\n",
      "          date        name        lat       lon  \\\n",
      "0  2025-01-01  LAP COFFEE  52.486768  13.35549   \n",
      "1  2025-01-02  LAP COFFEE  52.486768  13.35549   \n",
      "2  2025-01-03  LAP COFFEE  52.486768  13.35549   \n",
      "3  2025-01-04  LAP COFFEE  52.486768  13.35549   \n",
      "4  2025-01-05  LAP COFFEE  52.486768  13.35549   \n",
      "\n",
      "                                   address  pm25_aod_proxy  \\\n",
      "0  Akazienstraße 3A, 10823 Berlin, Germany             NaN   \n",
      "1  Akazienstraße 3A, 10823 Berlin, Germany             NaN   \n",
      "2  Akazienstraße 3A, 10823 Berlin, Germany             NaN   \n",
      "3  Akazienstraße 3A, 10823 Berlin, Germany             NaN   \n",
      "4  Akazienstraße 3A, 10823 Berlin, Germany             NaN   \n",
      "\n",
      "                    geometry weather_date  temp_max  temp_min  precip_mm  \\\n",
      "0  POINT (13.35549 52.48677)   2025-01-01       6.9       0.5        0.0   \n",
      "1  POINT (13.35549 52.48677)   2025-01-02       6.8       1.2        4.0   \n",
      "2  POINT (13.35549 52.48677)   2025-01-03       2.6      -1.2        4.6   \n",
      "3  POINT (13.35549 52.48677)   2025-01-04       0.8      -2.3        0.0   \n",
      "4  POINT (13.35549 52.48677)   2025-01-05       0.4      -2.4        8.8   \n",
      "\n",
      "   cafe_rating  cafe_user_ratings_total  season  ndvi  nightlight  \\\n",
      "0          4.7                      151  Winter   NaN   23.290001   \n",
      "1          4.7                      151  Winter   NaN   23.290001   \n",
      "2          4.7                      151  Winter   NaN   23.290001   \n",
      "3          4.7                      151  Winter   NaN   23.290001   \n",
      "4          4.7                      151  Winter   NaN   23.290001   \n",
      "\n",
      "                 cafe_place_id  elevation_m  parks_count_1km  \\\n",
      "0  ChIJGzWI8E5RqEcRYF2oui3pSKc         45.0               11   \n",
      "1  ChIJGzWI8E5RqEcRYF2oui3pSKc         45.0               11   \n",
      "2  ChIJGzWI8E5RqEcRYF2oui3pSKc         45.0               11   \n",
      "3  ChIJGzWI8E5RqEcRYF2oui3pSKc         45.0               11   \n",
      "4  ChIJGzWI8E5RqEcRYF2oui3pSKc         45.0               11   \n",
      "\n",
      "   open_bars_count_500m  \n",
      "0                    12  \n",
      "1                    12  \n",
      "2                    12  \n",
      "3                    12  \n",
      "4                    12  \n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Explore and Merge LAP Coffee Datasets (with PM2.5 and Parks)\n",
    "# \n",
    "# This notebook will:\n",
    "# 1. Load all GeoPackages\n",
    "# 2. Inspect structure and date ranges\n",
    "# 3. Merge daily and static datasets (including PM2.5 and parks)\n",
    "# 4. Keep only nearest park per address\n",
    "# 5. Ensure full daily coverage from 2025-01-01\n",
    "# 6. Deduplicate rating/user_ratings_total/place_id columns\n",
    "# 7. Save final CSV for dbt\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1️⃣ Import libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2️⃣ Define file paths\n",
    "data_dir = Path(\"/Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed\")\n",
    "\n",
    "gpkg_files = {\n",
    "    \"airquality\": data_dir / \"lap_locations_pm25_daily.gpkg\",  # PM2.5\n",
    "    \"elevation\": data_dir / \"lap_locations_elevation.gpkg\",\n",
    "    \"weather\": data_dir / \"lap_locations_historical_weather.gpkg\",\n",
    "    \"ndvi\": data_dir / \"lap_locations_ndvi_daily.gpkg\",\n",
    "    \"nightlights\": data_dir / \"lap_locations_nightlights_daily.gpkg\",\n",
    "    # UPDATED: File name uses 'lap_locations_with_all_bars.gpkg'\n",
    "    \"open_bars\": data_dir / \"lap_locations_with_open_bars.gpkg\", \n",
    "    \"parks\": data_dir / \"lap_locations_with_park_counts.gpkg\"  # Parks\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3️⃣ Load GeoPackages\n",
    "gdfs = {}\n",
    "for name, path in gpkg_files.items():\n",
    "    print(f\"Loading {name} from {path} ...\")\n",
    "    try:\n",
    "        gdfs[name] = gpd.read_file(path, layer=\"lap_coffee\")\n",
    "        print(f\"{name}: {gdfs[name].shape[0]} rows, columns: {list(gdfs[name].columns)}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR: Could not load {name} from {path}. Skipping this file. Error: {e}\\n\")\n",
    "        # Ensure the key is removed if loading fails to prevent KeyErrors later\n",
    "        del gpkg_files[name]\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4️⃣ Check date ranges\n",
    "for name, gdf in gdfs.items():\n",
    "    print(f\"### {name}\")\n",
    "    if \"date\" in gdf.columns:\n",
    "        print(\"Date range:\", gdf[\"date\"].min(), \"-\", gdf[\"date\"].max())\n",
    "    if \"weather_date\" in gdf.columns:\n",
    "        print(\"Weather date range:\", gdf[\"weather_date\"].min(), \"-\", gdf[\"weather_date\"].max())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5️⃣ Normalize date columns\n",
    "if \"weather\" in gdfs and \"weather_date\" in gdfs[\"weather\"].columns:\n",
    "    gdfs[\"weather\"][\"date\"] = pd.to_datetime(gdfs[\"weather\"][\"weather_date\"]).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "for key in [\"airquality\", \"ndvi\", \"nightlights\"]:\n",
    "    if key in gdfs and \"date\" in gdfs[key].columns:\n",
    "        gdfs[key][\"date\"] = pd.to_datetime(gdfs[key][\"date\"]).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7️⃣ Merge daily datasets (airquality, weather, ndvi, nightlights)\n",
    "# Using \"airquality\" key for the initial merge (PM2.5).\n",
    "daily_merged = gdfs[\"airquality\"].copy()\n",
    "\n",
    "for name in [\"weather\", \"ndvi\", \"nightlights\"]:\n",
    "    if name in gdfs:\n",
    "        merge_df = gdfs[name].drop(columns=[\"geometry\", \"address\"], errors=\"ignore\")\n",
    "        daily_merged = daily_merged.merge(\n",
    "            merge_df,\n",
    "            on=[\"name\", \"lat\", \"lon\", \"date\"],\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", f\"_{name}\")\n",
    "        )\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8️⃣ Merge static datasets (elevation, parks, open_bars)\n",
    "# Only includes elevation, parks, and open_bars.\n",
    "for name in [\"elevation\", \"parks\", 'open_bars']:\n",
    "    if name in gdfs:\n",
    "        merge_df = gdfs[name].drop(columns=[\"geometry\", \"address\"], errors=\"ignore\")\n",
    "        daily_merged = daily_merged.merge(\n",
    "            merge_df,\n",
    "            on=[\"name\", \"lat\", \"lon\"],\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", f\"_{name}\")\n",
    "        )\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9️⃣ Clean duplicate metadata columns\n",
    "duplicate_cols = [c for c in daily_merged.columns if any(x in c for x in [\"rating_\", \"user_ratings_total_\", \"place_id_\"])]\n",
    "\n",
    "if duplicate_cols:\n",
    "    print(\"Removing duplicate columns:\", duplicate_cols)\n",
    "    daily_merged = daily_merged.drop(columns=duplicate_cols, errors=\"ignore\")\n",
    "\n",
    "rename_map = {\n",
    "    \"rating\": \"cafe_rating\",\n",
    "    \"user_ratings_total\": \"cafe_user_ratings_total\",\n",
    "    \"place_id\": \"cafe_place_id\"\n",
    "}\n",
    "daily_merged = daily_merged.rename(columns=rename_map)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 🔟 Generate geometry column\n",
    "daily_merged = gpd.GeoDataFrame(\n",
    "    daily_merged,\n",
    "    geometry=gpd.points_from_xy(daily_merged.lon, daily_merged.lat),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1️⃣1️⃣ Ensure full date coverage per café (2025-01-01 onward)\n",
    "daily_merged[\"date\"] = pd.to_datetime(daily_merged[\"date\"])\n",
    "all_dates = pd.date_range(\"2025-01-01\", daily_merged[\"date\"].max())\n",
    "\n",
    "cafes = daily_merged[[\"name\", \"lat\", \"lon\", \"address\"]].drop_duplicates().reset_index(drop=True)\n",
    "full_index = pd.MultiIndex.from_product([cafes.index, all_dates], names=[\"cafe_idx\", \"date\"])\n",
    "full_df = pd.DataFrame(index=full_index).reset_index()\n",
    "\n",
    "full_df = full_df.merge(cafes.reset_index(), left_on=\"cafe_idx\", right_on=\"index\", how=\"left\")\n",
    "full_df = full_df.drop(columns=[\"cafe_idx\", \"index\"])\n",
    "\n",
    "full_df[\"date\"] = pd.to_datetime(full_df[\"date\"])\n",
    "daily_merged[\"date\"] = pd.to_datetime(daily_merged[\"date\"])\n",
    "\n",
    "daily_merged = full_df.merge(\n",
    "    daily_merged,\n",
    "    on=[\"name\", \"lat\", \"lon\", \"address\", \"date\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"✅ Expanded dataset covers {len(all_dates)} days × {len(cafes)} cafes = {len(all_dates) * len(cafes):,} rows\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1️⃣2️⃣ Convert date to string (for dbt / CSV)\n",
    "daily_merged[\"date\"] = daily_merged[\"date\"].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1️⃣3️⃣ Save final merged dataset\n",
    "output_csv = data_dir / \"lap_locations_final_merged.csv\"\n",
    "daily_merged.to_csv(output_csv, index=False)\n",
    "print(f\"✅ Merged dataset saved: {output_csv}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1️⃣4️⃣ Quick summary\n",
    "print(\"Columns:\", list(daily_merged.columns))\n",
    "print(\"Number of rows:\", daily_merged.shape[0])\n",
    "print(\"Sample rows:\\n\", daily_merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lapgee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
