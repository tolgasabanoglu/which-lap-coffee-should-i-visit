{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading airquality from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_airquality_daily.gpkg ...\n",
      "airquality: 9536 rows, columns: ['name', 'address', 'lat', 'lon', 'date', 'variable', 'value', 'geometry']\n",
      "\n",
      "Loading elevation from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_elevation.gpkg ...\n",
      "elevation: 16 rows, columns: ['name', 'address', 'lat', 'lon', 'rating', 'user_ratings_total', 'place_id', 'elevation_m', 'geometry']\n",
      "\n",
      "Loading weather from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_historical_weather.gpkg ...\n",
      "weather: 4768 rows, columns: ['weather_date', 'temp_max', 'temp_min', 'precip_mm', 'name', 'address', 'lat', 'lon', 'rating', 'user_ratings_total', 'season', 'geometry']\n",
      "\n",
      "Loading ndvi from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_ndvi_daily.gpkg ...\n",
      "ndvi: 4752 rows, columns: ['name', 'address', 'lat', 'lon', 'date', 'ndvi', 'geometry']\n",
      "\n",
      "Loading nightlights from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_nightlights_daily.gpkg ...\n",
      "nightlights: 4752 rows, columns: ['name', 'address', 'lat', 'lon', 'date', 'nightlight', 'geometry']\n",
      "\n",
      "Loading toilets from /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_with_toilets.gpkg ...\n",
      "toilets: 226 rows, columns: ['name', 'address', 'lat', 'lon', 'rating', 'user_ratings_total', 'place_id', 'toilet_name', 'toilet_lat', 'toilet_lon', 'toilet_distance_m', 'geometry']\n",
      "\n",
      "### airquality\n",
      "Date range: 2025-01-01 00:00:00 - 2025-10-25 00:00:00\n",
      "\n",
      "\n",
      "### elevation\n",
      "\n",
      "\n",
      "### weather\n",
      "Weather date range: 2025-01-01 - 2025-10-25\n",
      "\n",
      "\n",
      "### ndvi\n",
      "Date range: 2025-01-01 - 2025-10-24\n",
      "\n",
      "\n",
      "### nightlights\n",
      "Date range: 2025-01-01 - 2025-10-24\n",
      "\n",
      "\n",
      "### toilets\n",
      "\n",
      "\n",
      "Pivoted air quality columns: ['name', 'lat', 'lon', 'date', 'address', 'NO2', 'O3']\n",
      "After filtering, toilets dataset shape: (16, 12)\n",
      "✅ Expanded dataset now covers 296 days × 16 cafes = 4,736 rows\n",
      "✅ Merged dataset saved as CSV: /Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed/lap_locations_final_merged.csv\n",
      "Columns: ['date', 'name', 'lat', 'lon', 'address', 'NO2', 'O3', 'weather_date', 'temp_max', 'temp_min', 'precip_mm', 'rating_x', 'user_ratings_total_x', 'season', 'ndvi', 'nightlight', 'rating_y', 'user_ratings_total_y', 'place_id_x', 'elevation_m', 'rating', 'user_ratings_total', 'place_id_y', 'toilet_name', 'toilet_lat', 'toilet_lon', 'toilet_distance_m', 'geometry']\n",
      "Number of rows: 4736\n",
      "Sample rows:\n",
      "          date        name        lat        lon  \\\n",
      "0  2025-01-01  LAP COFFEE  52.479598  13.437743   \n",
      "1  2025-01-02  LAP COFFEE  52.479598  13.437743   \n",
      "2  2025-01-03  LAP COFFEE  52.479598  13.437743   \n",
      "3  2025-01-04  LAP COFFEE  52.479598  13.437743   \n",
      "4  2025-01-05  LAP COFFEE  52.479598  13.437743   \n",
      "\n",
      "                                       address       NO2        O3  \\\n",
      "0  Karl-Marx-Straße 101, 12043 Berlin, Germany       NaN  0.133417   \n",
      "1  Karl-Marx-Straße 101, 12043 Berlin, Germany  0.000028  0.145202   \n",
      "2  Karl-Marx-Straße 101, 12043 Berlin, Germany -0.000028  0.159655   \n",
      "3  Karl-Marx-Straße 101, 12043 Berlin, Germany       NaN  0.143945   \n",
      "4  Karl-Marx-Straße 101, 12043 Berlin, Germany       NaN  0.123235   \n",
      "\n",
      "  weather_date  temp_max  temp_min  ...                   place_id_x  \\\n",
      "0   2025-01-01       6.9       0.5  ...  ChIJbd-SFeFPqEcRjv6IFtDEPL8   \n",
      "1   2025-01-02       6.8       1.1  ...  ChIJbd-SFeFPqEcRjv6IFtDEPL8   \n",
      "2   2025-01-03       2.5      -1.3  ...  ChIJbd-SFeFPqEcRjv6IFtDEPL8   \n",
      "3   2025-01-04       0.8      -2.4  ...  ChIJbd-SFeFPqEcRjv6IFtDEPL8   \n",
      "4   2025-01-05       0.3      -2.5  ...  ChIJbd-SFeFPqEcRjv6IFtDEPL8   \n",
      "\n",
      "   elevation_m  rating user_ratings_total                   place_id_y  \\\n",
      "0         44.0     4.4               61.0  ChIJbd-SFeFPqEcRjv6IFtDEPL8   \n",
      "1         44.0     4.4               61.0  ChIJbd-SFeFPqEcRjv6IFtDEPL8   \n",
      "2         44.0     4.4               61.0  ChIJbd-SFeFPqEcRjv6IFtDEPL8   \n",
      "3         44.0     4.4               61.0  ChIJbd-SFeFPqEcRjv6IFtDEPL8   \n",
      "4         44.0     4.4               61.0  ChIJbd-SFeFPqEcRjv6IFtDEPL8   \n",
      "\n",
      "                                    toilet_name  toilet_lat  toilet_lon  \\\n",
      "0  Öffentliche Toilette mit kostenlosen Pissoir   52.498992   13.443021   \n",
      "1  Öffentliche Toilette mit kostenlosen Pissoir   52.498992   13.443021   \n",
      "2  Öffentliche Toilette mit kostenlosen Pissoir   52.498992   13.443021   \n",
      "3  Öffentliche Toilette mit kostenlosen Pissoir   52.498992   13.443021   \n",
      "4  Öffentliche Toilette mit kostenlosen Pissoir   52.498992   13.443021   \n",
      "\n",
      "  toilet_distance_m                  geometry  \n",
      "0         71.639908  POINT (13.43774 52.4796)  \n",
      "1         71.639908  POINT (13.43774 52.4796)  \n",
      "2         71.639908  POINT (13.43774 52.4796)  \n",
      "3         71.639908  POINT (13.43774 52.4796)  \n",
      "4         71.639908  POINT (13.43774 52.4796)  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Explore and Merge LAP Coffee Datasets\n",
    "# \n",
    "# This notebook will:\n",
    "# 1. Load all GeoPackages\n",
    "# 2. Inspect structure and date ranges\n",
    "# 3. Pivot air quality\n",
    "# 4. Merge daily and static datasets\n",
    "# 5. Keep only nearest toilet per address\n",
    "# 6. Ensure full daily coverage from 2025-01-01\n",
    "# 7. Deduplicate rating/user_ratings_total/place_id columns\n",
    "# 8. Save final CSV for dbt\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1️⃣ Import libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2️⃣ Define file paths\n",
    "data_dir = Path(\"/Users/tolgasabanoglu/Desktop/github/which-lap-coffee-should-i-visit/data/processed\")\n",
    "\n",
    "gpkg_files = {\n",
    "    \"airquality\": data_dir / \"lap_locations_airquality_daily.gpkg\",\n",
    "    \"elevation\": data_dir / \"lap_locations_elevation.gpkg\",\n",
    "    \"weather\": data_dir / \"lap_locations_historical_weather.gpkg\",\n",
    "    \"ndvi\": data_dir / \"lap_locations_ndvi_daily.gpkg\",\n",
    "    \"nightlights\": data_dir / \"lap_locations_nightlights_daily.gpkg\",\n",
    "    \"toilets\": data_dir / \"lap_locations_with_toilets.gpkg\"\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3️⃣ Load GeoPackages\n",
    "gdfs = {}\n",
    "for name, path in gpkg_files.items():\n",
    "    print(f\"Loading {name} from {path} ...\")\n",
    "    gdfs[name] = gpd.read_file(path, layer=\"lap_coffee\")\n",
    "    print(f\"{name}: {gdfs[name].shape[0]} rows, columns: {list(gdfs[name].columns)}\\n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4️⃣ Check date ranges\n",
    "for name, gdf in gdfs.items():\n",
    "    print(f\"### {name}\")\n",
    "    if \"date\" in gdf.columns:\n",
    "        print(\"Date range:\", gdf[\"date\"].min(), \"-\", gdf[\"date\"].max())\n",
    "    if \"weather_date\" in gdf.columns:\n",
    "        print(\"Weather date range:\", gdf[\"weather_date\"].min(), \"-\", gdf[\"weather_date\"].max())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5️⃣ Normalize date columns\n",
    "if \"weather\" in gdfs:\n",
    "    if \"weather_date\" in gdfs[\"weather\"].columns:\n",
    "        gdfs[\"weather\"][\"date\"] = pd.to_datetime(gdfs[\"weather\"][\"weather_date\"]).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "for key in [\"airquality\", \"ndvi\", \"nightlights\"]:\n",
    "    if \"date\" in gdfs[key].columns:\n",
    "        gdfs[key][\"date\"] = pd.to_datetime(gdfs[key][\"date\"]).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6️⃣ Pivot air quality to wide format\n",
    "air_wide = gdfs[\"airquality\"].pivot_table(\n",
    "    index=[\"name\", \"lat\", \"lon\", \"date\", \"address\"],\n",
    "    columns=\"variable\",\n",
    "    values=\"value\"\n",
    ").reset_index()\n",
    "\n",
    "print(\"Pivoted air quality columns:\", list(air_wide.columns))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7️⃣ Keep only nearest toilet per address\n",
    "toilets_gdf = gdfs[\"toilets\"].copy()\n",
    "toilets_gdf = toilets_gdf.loc[toilets_gdf.groupby(\"address\")[\"toilet_distance_m\"].idxmin()]\n",
    "gdfs[\"toilets\"] = toilets_gdf\n",
    "print(\"After filtering, toilets dataset shape:\", gdfs[\"toilets\"].shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8️⃣ Merge daily datasets\n",
    "daily_merged = air_wide.copy()\n",
    "\n",
    "for name in [\"weather\", \"ndvi\", \"nightlights\"]:\n",
    "    merge_df = gdfs[name].drop(columns=[\"geometry\", \"address\"], errors=\"ignore\")\n",
    "    daily_merged = daily_merged.merge(\n",
    "        merge_df,\n",
    "        on=[\"name\", \"lat\", \"lon\", \"date\"],\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", f\"_{name}\")\n",
    "    )\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9️⃣ Merge static datasets\n",
    "for name in [\"elevation\", \"toilets\"]:\n",
    "    merge_df = gdfs[name].drop(columns=[\"geometry\", \"address\"], errors=\"ignore\")\n",
    "    daily_merged = daily_merged.merge(\n",
    "        merge_df,\n",
    "        on=[\"name\", \"lat\", \"lon\"],\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", f\"_{name}\")\n",
    "    )\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 🔟 Clean duplicate metadata columns\n",
    "# Prefer elevation data for static attributes\n",
    "duplicate_cols = [c for c in daily_merged.columns if any(x in c for x in [\"rating_\", \"user_ratings_total_\", \"place_id_\"])]\n",
    "\n",
    "if duplicate_cols:\n",
    "    print(\"Removing duplicate columns:\", duplicate_cols)\n",
    "    daily_merged = daily_merged.drop(columns=duplicate_cols, errors=\"ignore\")\n",
    "\n",
    "# Also rename base columns cleanly\n",
    "rename_map = {\n",
    "    \"rating\": \"cafe_rating\",\n",
    "    \"user_ratings_total\": \"cafe_user_ratings_total\",\n",
    "    \"place_id\": \"cafe_place_id\"\n",
    "}\n",
    "daily_merged = daily_merged.rename(columns=rename_map)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1️⃣1️⃣ Generate geometry column\n",
    "daily_merged = gpd.GeoDataFrame(\n",
    "    daily_merged,\n",
    "    geometry=gpd.points_from_xy(daily_merged.lon, daily_merged.lat),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1️⃣2️⃣ Ensure full date coverage per café (2025-01-01 onward)\n",
    "daily_merged[\"date\"] = pd.to_datetime(daily_merged[\"date\"])\n",
    "all_dates = pd.date_range(\"2025-01-01\", daily_merged[\"date\"].max())\n",
    "\n",
    "cafes = daily_merged[[\"name\", \"lat\", \"lon\", \"address\"]].drop_duplicates().reset_index(drop=True)\n",
    "full_index = pd.MultiIndex.from_product([cafes.index, all_dates], names=[\"cafe_idx\", \"date\"])\n",
    "full_df = pd.DataFrame(index=full_index).reset_index()\n",
    "\n",
    "full_df = full_df.merge(cafes.reset_index(), left_on=\"cafe_idx\", right_on=\"index\", how=\"left\")\n",
    "full_df = full_df.drop(columns=[\"cafe_idx\", \"index\"])\n",
    "\n",
    "full_df[\"date\"] = pd.to_datetime(full_df[\"date\"])\n",
    "daily_merged[\"date\"] = pd.to_datetime(daily_merged[\"date\"])\n",
    "\n",
    "daily_merged = full_df.merge(\n",
    "    daily_merged,\n",
    "    on=[\"name\", \"lat\", \"lon\", \"address\", \"date\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"✅ Expanded dataset covers {len(all_dates)} days × {len(cafes)} cafes = {len(all_dates) * len(cafes):,} rows\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1️⃣3️⃣ Convert date to string (for dbt / CSV)\n",
    "daily_merged[\"date\"] = daily_merged[\"date\"].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1️⃣4️⃣ Save final merged dataset\n",
    "output_csv = data_dir / \"lap_locations_final_merged.csv\"\n",
    "daily_merged.to_csv(output_csv, index=False)\n",
    "print(f\"✅ Merged dataset saved: {output_csv}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1️⃣5️⃣ Quick summary\n",
    "print(\"Columns:\", list(daily_merged.columns))\n",
    "print(\"Number of rows:\", daily_merged.shape[0])\n",
    "print(\"Sample rows:\\n\", daily_merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lapgee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
